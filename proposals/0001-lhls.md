- Feature Name: Low-Latency Streaming
- Start Date: 2018-08-18
- RFC PR: (leave this empty)
- Hls.js Issue: (leave this empty)

# Summary
[summary]: #summary

Low-latency HLS (LHLS) proposes to reduce the latency from the edge of a live stream. Hls.js incurs significant latency penalties from it's current architecture; and also incurs another penalty from the current method of delivering segments over HTTP. This RFC proposes modifications to Hls.js's architecture to support progressive downloading, parsing, and buffering of media segments. This proposal also aims to gain consensus on how transcoders shall signal and deliver LHLS streams to Hls.js so as to reduce latency.

# Motivation
[motivation]: #motivation

The current latency between capture and playback ("glass to glass") is prohibitive for live interactivity, and provides a poor experience for time-sensitive live events (such as sports). The introduction of low-latency streaming via HTTP in Hls.js would allow developers to build a cost-effective solution on top of a free, open, and proven client.

Furthermore, the introduction of a progressive streaming pipeline in Hls.js would improve performance not only for live but for VOD. Progressively buffering segments allows Hls.js to reduce it's TTFF (time to first frame), and by the same token reduce the rebuffering time caused by network instability.

# Guide-Level Explanation
[guide-level-explanation]: #guide-level-explanation


Low-latency streaming is used by Hls.js to stream MPEG2-TS segments which have not completed transcoding yet. Segments do not need to be complete to be buffered - each each segment contains a number of GOPs (group of pictures), and each GOP can be independently transmuxed and appended to MSE. Using HTTP chunked transfer encoding, Hls.js is able to maintain a persistent connection with a transcoding server; the server in turn is able to push partial segments to the client before completion. Additional reductions in latency are thanks to negotiating the TCP connection ahead of time the segment needs to be buffered.


Hls.js takes advantage of this feature when it detections a custom HLS tag prepending a segment URL. When Hls.js sees this tag, it makes a request using the Fetch API with streaming body responses. Each time Hls.js receives a chunk of data, it passes it through it's transcoding pipeline so that it may be buffered. Any samples which could not be decoded using the information in the present chunk is saved so that it may be used in the next. In this way Hls.js is able to stream segments throught it's pipeline instead of waiting for the whole thing.

Hls.js offers the developer the option to disable or enable low-latency streaming even while Hls.js is playing. This is made possible by the structure of the low-latency manifest. In addition to segments which have not been transcoded, an LHLS manifest also advertises segments which have already been transcoded. These segments conform to the HLS spec and require no extra work to buffer. When low-latency mode is disabled, Hls.js simply ignores any future-advertised segments. It is this feature which allows Hls.js to continue to function in browsers which do not support low-latency streaming, without requiring the transcoding service to create two versions of a manifest.
  
This RFC proposes changes to the top-level API of Hls.js; and also organizes the sub-subystem RFCs broken out from the main story. Please see the sections below for links to the sub-system RFCs.


# Reference-level explanation
[reference-level-explanation]: #reference-level-explanation

This section details how Hls.js interprets a low-latency manifest. Developers wishing to use LHLS must adhere to the conventions laid out within this section. "The client" here refers to Hls.js but is worded so that any MSE-based player may fulfill the same requirements.

## Glossary
- Client: An MSE-Based JS player such as Hls.js
- Server: The system comprising delivery, transcoding, cdn etc.; the party responsible for creating and serving the manifest
- Future segment: A segment which has been advertised but not transcoded
- Complete/normal segment: A segment which has been advertised and trasnscoded 

## Future Segment Advertising

The server may advertise zero or more future segments for the live period using the `EXT-X-PREFETCH` metadata tag. The tag must conform to the following format:

`#EXT-X-PREFETCH: ${url}`

To each future segment response, the server must append the `Transfer-Encoding: chunked` header. The server must maintain the persistent HTTP connection long enough for a client to receive the entire segment - at a minimum, this should be no less than the time from when the segment was first advertised to the time it has finished transcoding. If the server would "normally" advertise the same segment after it has once been future advertised, it must use the same URL as it did with the `EXT-X-PREFETCH` tag.

The client shall request all future segments according to the procedure defined in the Advanced Segment Downloader (see below).


## Normal Segment Advertising

The server may advertise zero or more segments which have been completely transcoded. These segments must not be advertised with the `EXT-X-PREFETCH` tag, and should be advertised before any future segments. These segments must conform to the HLS standard.

## Enabling and Disabling LHLS

The client may choose to build low-latency streaming with the capability to be enabled or disabled. If disabled, the client must not download future advertised segments; if enabled, the client may download these. To account for these cases, the server should always deliver complete segments alongside future segments.

## Measuring Latency

If a developer wishes to measure the total, or "glass-to-glass" latency of a stream, the server must add the `EXT-X-PROGRAM-DATE-TIME` (PDT) metadata to each segment, in the format detailed by [the spec](https://tools.ietf.org/html/draft-pantos-http-live-streaming-23#section-4.3.2.6). The timestamp should be as close to capture as possible to ensure accuracy {what is a good recommendation on "as close to capture as possible?}. This metadata must not be appended to segments future advertised with the `EXT-X-PREFETCH` tag.  The client shall measure accuracy using the following equations:

```
totalLatency = playerLatency + broadcastLatency

playerLatency = lastSegment.endTime - video.currentTime

broadcastLatency = lastSegment.endTime - wallclockTime
```

Where `wallclockTime` is the current time (in browsers, this is typically measured using `Date.now()`).

Where `lastSegment` is the last normally-advertised segment in the manifest, and `endTime` is it's PDT plus duration.


If the `EXT-X-PROGRAM-DATE-TIME` timestamp is not provided, the client may advertise `playerLatency` alone, or nothing at all.


## Example Manifest

The example below is a child manifest listing two normal segments and two future segments.

`URL: https://foo.com/bar.m3u8`
```
#EXTM3U
#EXT-X-VERSION:3
#EXT-X-TARGETDURATION:2
#EXT-X-PROGRAM-DATE-TIME:2018-09-05T20:59:06.531Z
#EXTINF:2.000
https://foo.com/bar/0.ts
#EXT-X-PROGRAM-DATE-TIME:2018-09-05T20:59:08.531Z
#EXTINF:2.000
https://foo.com/bar/1.ts

#EXT-X-PREFETCH:https://foo.com/bar/2.ts
#EXT-X-PREFETCH:https://foo.com/bar/3.ts
```
The next manifest request may return: 

```
#EXTM3U
#EXT-X-VERSION:3
#EXT-X-TARGETDURATION:2
#EXT-X-PROGRAM-DATE-TIME:2018-09-05T20:59:06.531Z
#EXTINF:2.000
https://foo.com/bar/1.ts
#EXT-X-PROGRAM-DATE-TIME:2018-09-05T20:59:08.531Z
#EXTINF:2.000
https://foo.com/bar/2.ts

#EXT-X-PREFETCH:https://foo.com/bar/3.ts
#EXT-X-PREFETCH:https://foo.com/bar/4.ts
```

Note how the future frag `#EXT-X-PREFETCH:https://foo.com/bar/2.ts` is now advertised as a normal segment with complete metadata.

## LHLS Subsystem RFCs
- [Progressive Streaming Engine]( ./0002-progressive-streaming.md)
- [Advanced Segment Downloader](./0003-advanced-segment-downloading.md)
- [LHLS-Aware ABR Controller]()
- [Live Edge Catch-Up Mechanism]()

# Drawbacks
[drawbacks]: #drawbacks

- This feature will require significant codebase changes and may introduce regressions.
- The proposed changes may make the codebase more complicated. Hls.js has an event-based architecture, in which events follow a sequential pattern (e.g. LOADING -> LOADED -> PARSED -> BUFFERED). LHLS will require events to be fired out of regular order (e.g. LOADING -> LOADING -> LOADED -> LOADING -> PARSED -> LOADED). A poor implementation may make codebase maintenance more difficult.

# Rationale and alternatives
[rationale-and-alternatives]: #rationale-and-alternatives

## The choice of HTTP
HTTP low-latency streaming (as opposed to alternative protocols like WebRTC) allows developers to leverage existing HTTP video delivery infrastructure. It is also more straightforward to implement in Hls.js itself. However, WebRTC would further reduce latency by eliminating 

## Prefetch flavor of LHLS
This proposal details an LHLS manifest which differs from the "traditional" format, in which all segments in the manifest are intended to be progressively downloaded. In this scheme there is no differentiation between complete segments and those in the process of transcoding.

The benefits of prefetching over this scheme are:

1. Backwards compatibility. Clients which do not support LHLS will discard future segments; good prefetch implementations should also have transcoded segments in-manifest for incompatible clients to play. Furthermore, transcoding services will not have to create two versions of a manifest (LHLS and not) to support all devices.
2. In-client LHLS selection. Developers will be able to disable or enable LHLS while the client is streaming. Developers may make this option available to the user so that they are able to choose an experience most beneficial to them.


And the downsides are:
1. Increased server complexity. The server must add custom metadata to the manifest, and the server must deliver (and differentiate) transcoded and future segments.
2. Increased client complexity. The client must be able to utilize both future and complete segments.


## What is the cost of not doing this?
Low-latency streaming is becoming increasingly desired. Larger companies such as Akamai, Wowza, and Periscope offer low-latency streaming solutions. However, these solutions are not free or open. Not implementing this feature in Hls.js would make it more difficult for all video developers to access an easy and effective LHLS solution; if LHLS becomes a basic feature in the future, not having a FOSS solution will drive people towards a closed solution. Furthermore, developing LHLS in the open allows everyone to participate in its development.

# Supported Environments
[supported-environments]: #supported-environments

Only browsers which support the Fetch API with streaming body responses are able to support LHLS. This includes:

- Chrome >= 63
- Edge >= 16
- Safari >= 11.1
- Firefox >= 57 (only behind a flag)

# Prior art
[prior-art]: #prior-art

- https://medium.com/@periscopecode/introducing-lhls-media-streaming-eb6212948bef
- https://speakerdeck.com/stswe/cmaf-low-latency-streaming-by-will-law-from-akamai
- https://www.wowza.com/products/capabilities/low-latency

# Unresolved questions
[unresolved-questions]: #unresolved-questions

## What parts of the design do you expect to resolve through the RFC process before this gets merged?
- ~~How transcoders should signal LHLS~~
- .ts or .fmp4 support (or both)
- Handling of trickier features (e.g. discontinuities)
- How to track bitrate for ABR
- How to catch up to the live edge after falling behind
- How long should the server maintain a segment connection for
- ~~How is latency measured?~~
- Should any functionality be made overrideable via config? If so, which ones? 
- ~~Should individual segments be marked as low-latency (like Twitch's PREFETCH metadata), or should the entire stream be low-latency?~~
- Should the manifest only update after the prefetch frags have completed? Can prefetch frags be repeated if they are not yet completed?
- How much data does a transcoder typically push? Is one GOP enough to buffer in MSE?
 
## What parts of the design do you expect to resolve through the implementation of this feature before stabilization?


## What related issues do you consider out of scope for this RFC that could be addressed in the future independently of the solution that comes out of this RFC?
- CMAF low latency segments
